<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.55.6" />
  

  
  
  
  
    
      
    
  
  <meta name="description" content="About This package includes:
 A discourse segmenter A discourse parser Evaluation metrics for discourse parsing  Download Document-level Discourse Parser for English
Demo Link
Installation Required for the discourse segmenter:
 Charniak&rsquo;s reranking parser. Put it in Tools/CharniakParserRerank and install it. Taggers from UIUC. Download POS tagger and shallow chunker [LBJPOS.jar, LBJChunk.jar, LBJ2.jar, LBJ2Library.jar] and put these in Tools/UIUC_TOOLs/ Install scikit-learn and scipy (instructions) Install java if not installed (instructions for Ubuntu) Make sure the Tools/SPADE_UTILS/bin/edubreak is set to executable.">

  
  <link rel="alternate" hreflang="en-us" href="https://ntunlpsg.github.io/project/parser/parser/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-115450637-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="https://ntunlpsg.github.io/index.xml" type="application/rss+xml" title="NTU-NLP">
  <link rel="feed" href="https://ntunlpsg.github.io/index.xml" type="application/rss+xml" title="NTU-NLP">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://ntunlpsg.github.io/project/parser/parser/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ntunlpsg">
  <meta property="twitter:creator" content="@ntunlpsg">
  
  <meta property="og:site_name" content="NTU-NLP">
  <meta property="og:url" content="https://ntunlpsg.github.io/project/parser/parser/">
  <meta property="og:title" content="Discourse Parser for English | NTU-NLP">
  <meta property="og:description" content="About This package includes:
 A discourse segmenter A discourse parser Evaluation metrics for discourse parsing  Download Document-level Discourse Parser for English
Demo Link
Installation Required for the discourse segmenter:
 Charniak&rsquo;s reranking parser. Put it in Tools/CharniakParserRerank and install it. Taggers from UIUC. Download POS tagger and shallow chunker [LBJPOS.jar, LBJChunk.jar, LBJ2.jar, LBJ2Library.jar] and put these in Tools/UIUC_TOOLs/ Install scikit-learn and scipy (instructions) Install java if not installed (instructions for Ubuntu) Make sure the Tools/SPADE_UTILS/bin/edubreak is set to executable."><meta property="og:image" content="https://ntunlpsg.github.io/img/dt1.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2016-04-28T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2016-04-28T00:00:00&#43;00:00">
  

  

  <title>Discourse Parser for English | NTU-NLP</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/"><img src="/img/ntunlp_final.png" alt="NTU-NLP"></a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#people">
            
            <span>People</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/publication/">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/resources/">
            
            <span>Resources</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/post/reading-group">
            
            <span>Reading Group</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/post/news">
            
            <span>News</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/post/talk">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article article-project" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  <img src="/img/dt1.png" class="article-banner" itemprop="image">
  <span class="article-header-caption">discourse parse tree</span>
</div>



  <div class="article-container">

    <div class="pub-title">
      <h1 itemprop="name">Discourse Parser for English</h1>
      <span class="pub-authors" itemprop="author">&nbsp;</span>
      <span class="pull-right">
        

      </span>
    </div>

    

    <div class="article-style" itemprop="articleBody">
      

<h3 id="about">About</h3>

<p>This package includes:</p>

<ul>
<li>A discourse segmenter</li>
<li>A discourse parser</li>
<li>Evaluation metrics for discourse parsing</li>
</ul>

<h3 id="download">Download</h3>

<p><a href="https://drive.google.com/file/d/1p6UWefyI7l2_nIj249UoaMAu1lOp5UQo/view?usp=sharing" target="_blank">Document-level Discourse Parser for English</a></p>

<h3 id="demo">Demo</h3>

<p><a href="http://alt.qcri.org/demos/Discourse_Parser_Demo/" target="_blank">Link</a></p>

<h3 id="installation">Installation</h3>

<p>Required for the discourse segmenter:</p>

<ol>
<li><a href="https://github.com/BLLIP/bllip-parser" target="_blank">Charniak&rsquo;s reranking parser</a>. Put it in Tools/CharniakParserRerank and install it.</li>
<li><a href="http://cogcomp.cs.illinois.edu/page/software" target="_blank">Taggers from UIUC</a>. Download POS tagger and shallow chunker [LBJPOS.jar, LBJChunk.jar, LBJ2.jar, LBJ2Library.jar] and put these in Tools/UIUC_TOOLs/</li>
<li>Install scikit-learn and scipy <a href="http://scikit-learn.org/stable/install.html" target="_blank">(instructions)</a></li>
<li>Install java if not installed <a href="https://help.ubuntu.com/community/Java" target="_blank">(instructions for Ubuntu)</a></li>
<li>Make sure the Tools/SPADE_UTILS/bin/edubreak is set to executable.</li>
</ol>

<p>Required for the discourse parser:</p>

<ol>
<li>Install wordNet (for example, On ubuntu you can write: apt-get install science-linguistics) and set the WNHOME environment variable to the WordNet directory. WNHOME should contain the dictionary files.</li>
<li>Install WordNet::QueryData (<a href="http://search.cpan.org/dist/WordNet-QueryData/QueryData.pm" target="_blank">http://search.cpan.org/dist/WordNet-QueryData/QueryData.pm</a>; also provided). To install it properly you may need to set the <code>$wnHomeUnix</code> and <code>$wnPrefixUnix</code> to the appropriate directories.</li>
</ol>

<h3 id="usage">Usage</h3>

<p>For parsing a raw text, you should run discourse segmenter followed by discourse parser.</p>

<p>Running the discourse segmenter:</p>

<p>$ python Discourse_Segmenter.py <infile>
If it shows errors in apply_model method in loading the model, then it is due to differnt versions of the logistic regression in sklearn. To overcome this, open the commented &ldquo;train_model&rdquo; in do_segment method and run the segmenter. This learns the model and saves it. If it runs once, you don&rsquo;t need to run train_model again. You should comment it to save time.</p>

<p>Running the discourse parser:</p>

<p>$ python Discourse_Parser.py <discourse segmented file></p>

<h3 id="download-1">Download</h3>

<p><a href="http://alt.qcri.org/tools/discourse-eval/releases/current/discourse_eval.tar.gz" target="_blank">Evaluation Metrics for Discourse Parsing</a>. Latest release.
Implementation of the standard evaluation metrics as described in <a href="http://mitpress.mit.edu/books/theory-and-practice-discourse-parsing-and-summarization's book" target="_blank">Dan Marcu&rsquo;s book</a>.</p>

<h3 id="usage-1">Usage</h3>

<ul>
<li>Extract Set.tar.gz.</li>

<li><p>Run the perl script:</p>

<pre><code>Perl ParsingAccuracyMeasuresDocLevelForSystems.pl path_to_sys_dir path_to_gold_dir res.out
</code></pre></li>
</ul>

<p>The main perl script takes three arguments:</p>

<ol>
<li><p>Path to the directory with the system annotations: The filenames should end with *. doc_dis, but you can change the code according to your need. Here is where you need to change:</p>

<pre><code>my @canFiles = grep /\w+\.doc_dis/, readdir(DIR);
</code></pre></li>

<li><p>Path to the Directory with the gold annotations: It assumes that the file names are the same as the system outputs (e.g., *.doc_dis).</p></li>

<li><p>The name of the output file: In the output file, it shows the results for the individual documents as well as the summary.</p></li>
</ol>

<p>A sample output file is attached. The parsed documents should have the same format as RST-DT.</p>

<h3 id="related-publications">Related publications</h3>

<hr />

<p>Shafiq Joty, Giuseppe Carenini, and Raymond Ng. 2015. CODRA: A Novel Discriminative Framework for Rhetorical Analysis. Computational Linguistics, Volume 41:3, MIT Press. [<a href="https://www.mitpressjournals.org/doi/abs/10.1162/COLI_a_00226" target="_blank">Link to PDF</a>]</p>

<pre><code>@article{joty-carenini-ng-cl-15,
  title=&quot;{CODRA: A Novel Discriminative Framework for Rhetorical Analysis}&quot;,
  author={Joty, Shafiq and Carenini, Giuseppe and Ng, Raymond T},
  journal = {Computational Linguistics},
  volume={41:3},
  publisher={MIT Press},
  pages={385-435},
  year={2015},
}
</code></pre>

<hr />

<p>Shafiq Joty, Giuseppe Carenini, Raymond Ng and Yashar Mehdad. Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013), Sofia, Bulgaria. [<a href="https://aclanthology.info/papers/P13-1048/p13-1048" target="_blank">Link to PDF</a>]</p>

<pre><code>@inproceedings{joty-carenini-ng-mehdad-acl-13,
  Title = {Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis},  
  Author = {Joty, Shafiq and Carenini, Giuseppe and Ng, Raymond T. and Mehdad, Yashar},
  Address = {Sofia, Bulgaria},
  Booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics},
  Numpages = {9},
  Publisher = {ACL},
  Series = {ACL-13},
  pages = {486-496},
  Year = {2013},
} 
</code></pre>

<hr />

<p>Shafiq Joty, Giuseppe Carenini and Raymond Ng. A Novel Discriminative Framework for Sentence-Level Discourse Analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and the Conference on Natural Language Learning (EMNLP-CoNLL 2012), Jeju, Korea. [<a href="http://www.aclweb.org/anthology/D12-1083" target="_blank">PDF</a>]</p>

<pre><code>@inproceedings{joty2012novel,
  title={A novel discriminative framework for sentence-level discourse analysis},
  author={Joty, Shafiq and Carenini, Giuseppe and Ng, Raymond T},
  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  Series = {EMNLP-CoNLL-12},
  pages={904-915},
  year={2012},
  organization={Association for Computational Linguistics}
}
</code></pre>

<h1 id="license">License</h1>

<p>The Discourse Parser is an Open Source Software, and is released under the Common Public License. You are welcome to use the code under the terms of the licence for research purposes ONLY, however please acknowledge its use with a citation given above in the Related publications.</p>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/discourse">discourse</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/parser">parser</a>
  
</div>




    
    
    

    
      
      
      
      

      
      
      
      
    

  </div>
</article>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

