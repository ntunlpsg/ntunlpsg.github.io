<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on NTU-NLP</title>
    <link>https://ntunlpsg.github.io/project/</link>
    <description>Recent content in Projects on NTU-NLP</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>ntunlp &amp;copy; 2020</copyright>
    <lastBuildDate>Sat, 01 May 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://ntunlpsg.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RST Parsing from Scratch</title>
      <link>https://ntunlpsg.github.io/project/naacl21-rst-parsing-resource/naacl21-rst-parsing-resource/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/naacl21-rst-parsing-resource/naacl21-rst-parsing-resource/</guid>
      <description>RST Parsing from Scratch This repository contains the source code of our paper RST Parsing from Scratch in NAACL 2021.
Requirements  python: 3.7 pytorch: 1.4 transformers: 3.0  Usage To train a discourse parser:
./*_train.sh  To predict discourse tree:
./*_predict.sh  Data Format  For end-to-end parsing from scratch (no sentence guidance): we need to create the data with dummy edu_break and doc_structure. Refer to create_sample_dummy_format_data.py and dummy_format_data/sample_rawtext_data_format For other parsing models: Refer to create_sample_dummy_format_data.</description>
    </item>
    
    <item>
      <title>Rethinking Coherence Modeling: Synthetic vs. Downstream Tasks</title>
      <link>https://ntunlpsg.github.io/project/coherence/coh-eval/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/coherence/coh-eval/</guid>
      <description>About This resource contains the information regarding code and data used for evaluation in &amp;ldquo;Rethinking Coherence Modeling: Synthetic vs. Downstream Tasks&amp;rdquo; paper (EACL 2021). Source code of evaluated coherence models We benchmark the performance of five coherence models. For each of the coherence models, we conducted experiments with publicly available codes from the respective authors. Links are given below:
 Entity Grid Neural Entity Grid Lexicalized Neural Entity Grid Transferable Neural Model Unified Neural Model  Datasets  Machine Translation Evaluation Dataset: We use the reference and the system translations provided by WMT2017-2018 as our test data, under the assumption that the reference translations are more coherent than the system translations.</description>
    </item>
    
    <item>
      <title>DAGA: Data Augmentation with a Generation Approach for Low-resource Tagging Tasks</title>
      <link>https://ntunlpsg.github.io/project/daga/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0800</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/daga/</guid>
      <description>Github
DAGA This is the source code of our method proposed in paper &amp;ldquo;DAGA: Data Augmentation with a Generation Approach for Low-resource Tagging Tasks&amp;rdquo; accepted by EMNLP 2020.
Examples flair_seq_tagger: sequense tagging model cd flair_seq_tagger; python train_tagger.py \ --data_dir PATH/TO/TRAIN_DIR \ --train_file train.txt \ --dev_file dev.txt \ --data_columns text ner \ --model_dir ./model \ --comment_symbol &amp;quot;__label__&amp;quot; \ --embeddings_file PATH/TO/emb \ --optim adam \ --learning_rate 0.001 --min_learning_rate 0.00001 \ --patience 2 \ --max_epochs 100 \ --hidden_size 512 \ --mini_batch_size 32 \ --gpuid 0  lstm-lm: LSTM language model  train lstm-lm on linearized sequences ``` cd lstm-lm;  python train.</description>
    </item>
    
    <item>
      <title>Evaluating Pronominal Anaphora in Machine Translation: An Evaluation Measure and a Test-suite</title>
      <link>https://ntunlpsg.github.io/project/discomt/eval-anaphora/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/discomt/eval-anaphora/</guid>
      <description>This repository contains the data and source code of our paper &amp;ldquo;Evaluating Pronominal Anaphora in Machine Translation: An Evaluation Measure and a Test-suite&amp;rdquo; in EMNLP-IJCNLP 2019.
Prerequisites * PyTorch 0.4 or higher * Python 3 * AllenNLP * SQLite3  Datasets - Training/Development/Testing The training data consists of system translations vs. reference text from WMT 2011-15. There are two versions of the development data: one with unique system translations vs.</description>
    </item>
    
    <item>
      <title>A Unified Neural Coherence Model</title>
      <link>https://ntunlpsg.github.io/project/coherence/n-coh-emnlp19/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/coherence/n-coh-emnlp19/</guid>
      <description>About This resource contains the source code of &amp;ldquo;A Unified Neural Coherence Model&amp;rdquo; paper (EMNLP-IJCNLP 2019, Hong Kong, China). Source code Link to source code
Datasets Regard to WSJ license, we only share the script to generate local and global coherence dataset from the WSJ dataset.
Citation Please cite our paper if you found the resources in this repository useful.
@inproceedings{moon-etal-2019-unified, title = &amp;quot;A Unified Neural Coherence Model&amp;quot;, author = &amp;quot;Moon, Han Cheol and Mohiuddin, Tasnim and Joty, Shafiq and Xu, Chi&amp;quot;, booktitle = &amp;quot;Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)&amp;quot;, month = nov, year = &amp;quot;2019&amp;quot;, address = &amp;quot;Hong Kong, China&amp;quot;, publisher = &amp;quot;Association for Computational Linguistics&amp;quot;, url = &amp;quot;https://www.</description>
    </item>
    
    <item>
      <title>Hierarchical Pointer Net Parsing</title>
      <link>https://ntunlpsg.github.io/project/parser/ptrnet-depparser/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/parser/ptrnet-depparser/</guid>
      <description>This is the source code of our dependency parser proposed in paper &amp;ldquo;Hierarchical Pointer Net Parsing&amp;rdquo; accepted by EMNLP 2019. Git Repository: https://github.com/ntunlp/ptrnet-depparser.git
Requirements Python 2.7, PyTorch &amp;gt;=0.3.0, Gensim &amp;gt;= 0.12.0
Models We have implemented the below models in this project, which can be found in ./neuronlp2/models/parsing2.py:
 HPtrNetPSTGate: In each step, decoder receives hidden states from sibling, parent and previous step. Use Gate described in the paper.
 HPtrNetPSTSGate: In each step, decoder receives hidden states from sibling, parent and previous step.</description>
    </item>
    
    <item>
      <title>Discourse Processing and Its Applications --- Tutoral at ACL-2019</title>
      <link>https://ntunlpsg.github.io/project/acl19tutorial/</link>
      <pubDate>Mon, 15 Jul 2019 00:00:00 +0800</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/acl19tutorial/</guid>
      <description>Time: 28 July 9:00 - 12:30  Location: TBA 
Slides: Part-1, Part-2
   Tutors              Shafiq Joty Giuseppe Carenini Raymond T Ng Gabriel Murray    Tutorial Abstract Discourse processing is a suite of Natural Language Processing (NLP) tasks to uncover linguistic structures from texts at several levels, which can support many downstream applications. This involves identifying the topic structure, the coherence structure, the coreference structure, and the conversation structure for conversational discourse.</description>
    </item>
    
    <item>
      <title>Unsupervised Word Translation</title>
      <link>https://ntunlpsg.github.io/project/unsup-word-translation/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/unsup-word-translation/</guid>
      <description>About This resource contains the source code of our NAACL-HLT 2019 paper entitled Revisiting Adversarial Autoencoder for Unsupervised Word Translation with Cycle Consistency and Improved Training. Source code Link to source code
Datasets  Conneau et al. (2018) Dataset: Consists of FastText monolingual embeddings of 300 dimensions trained on Wikipedia monolingual corpus and gold dictionaries for 110 language pairs. Dinu-Artexe dataset: Consists of monolingual embeddings of 300 dimension for English, Italian and Spanish.</description>
    </item>
    
    <item>
      <title>Malay-English Neural Machine Translation System.</title>
      <link>https://ntunlpsg.github.io/project/malay-english-neural-machine-translator/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/malay-english-neural-machine-translator/</guid>
      <description>This is a tool to translate an English sentence into Malay and vice versa. Developing a translation tool for low-resource languages like Malay has always been a challenge. The main challenge comes from the fact that machine translation systems typically rely on a huge amount of sentence-parallel data, and creating such datasets is an expensive process. In our work, we collected parallel datasets from various sources including News, OpenSubtitiles (OPUS), Ted talks, and Youtube video.</description>
    </item>
    
    <item>
      <title>Discourse Processing and Its Applications in Text Mining --- Tutoral at ICDM-2018</title>
      <link>https://ntunlpsg.github.io/project/icdmtutorial/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0800</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/icdmtutorial/</guid>
      <description>Time: 18 Nov 3:40 - 5:40 Location: Virgo IV (Resort World Sentosa), Singapore. 
Slides: Part-1, Part-2
   Tutors              Shafiq Joty Giuseppe Carenini Raymond T Ng Gabriel Murray    Tutorial Abstract Discourse processing is a suite of Natural Language Processing (NLP) tasks to uncover linguistic structures from texts at several levels, which can support many text mining applications.</description>
    </item>
    
    <item>
      <title>Coherence Modeling of Asynchronus Conversations</title>
      <link>https://ntunlpsg.github.io/project/coherence/n-coh-acl18/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/coherence/n-coh-acl18/</guid>
      <description>About This resource contains the source code of &amp;ldquo;Coherence Modeling of Asynchronus Conversations: A Neural Entity Grid Approach&amp;rdquo; paper. Source code Link to source code
Datasets Regard to WSJ and CNET license, we only provide entity grid files extracted using BrownCoherence toolkit.
Citation If you use the entity grid files (including permutations) and the code, please refer to our ACL 2018 paper.
 @InProceedings{joty-mohiuddin-nguyen-acl-18, title=&amp;quot;{Coherence Modeling of Asynchronous Conversations: A Neural Entity Grid Approach}&amp;quot;, author={Tasnim Mohiuddin and Shafiq Joty and Dat Nguyen}, booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics}, series ={ACL&#39;18}, publisher={Association for Computational Linguistics}, address = {Melbourne, Australia}, pages={xx--xx}, url = {}, year={2018} }  Licence MIT licence.</description>
    </item>
    
    <item>
      <title>A Unified Linear-Time Framework for Sentence-Level Discourse Parsing</title>
      <link>https://ntunlpsg.github.io/project/parser/pointer-net-parser/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/parser/pointer-net-parser/</guid>
      <description>This repository contains the source code of our paper &amp;ldquo;A Unified Linear-Time Framework for Sentence-Level Discourse Parsing&amp;rdquo; in ACL 2019.
 Getting Started These instructions will help you to run our unified discourse parser based on RST dataset.
Prerequisites * PyTorch 0.4 or higher * Python 3 * AllenNLP  Dataset We train and evaluate the model with the standard RST Discourse Treebank (RST-DT) corpus. * Segmenter: we utilize all 7673 sentences for training and 991 sentences for testing.</description>
    </item>
    
    <item>
      <title>Community Question Answering System</title>
      <link>https://ntunlpsg.github.io/project/community-qa/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/community-qa/</guid>
      <description>About This Resource includes:
 A live demonstration of question-answering system. Relevant publications for question-answering system.  Demo link to live Qatar Living system
This search tool helps you to find good answers to your question by searching through previously asked questions in the Qatarliving forum. The underlying technology is developed at QCRI and MIT in collaboration with Qatar Living.
Watch the video to learn more:
  Relevant publications Enamul Hoque, Shafiq Joty, Lluís Màrquez, and Giuseppe Carenini.</description>
    </item>
    
    <item>
      <title>Deep Learning for Crisis Computing</title>
      <link>https://ntunlpsg.github.io/project/crisis-computing/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/crisis-computing/</guid>
      <description>About This repository will host Python implementation of a number of deep neural networks classifiers for the classification of crisis-related data on Twitter.
 Requirementes:
python 2.7 numpy, scikit-learn keras, tensorflow or theano backend  Dataset and Pre-process A sample of tweet data (data/sample.csv) is a .csv format with three columns
First, we need to pre-process tweets data: remove urls, special characters, lowercasing… - python data_helpers/preprocess.py data/sample.csv Split pre-processed data (data/sample_prccd.</description>
    </item>
    
    <item>
      <title>Discourse Parser for English</title>
      <link>https://ntunlpsg.github.io/project/parser/parser/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/parser/parser/</guid>
      <description>About This package includes:
 A discourse segmenter A discourse parser Evaluation metrics for discourse parsing  Download Document-level Discourse Parser for English
Demo Link
Installation Required for the discourse segmenter:
 Charniak&amp;rsquo;s reranking parser. Put it in Tools/CharniakParserRerank and install it. Taggers from UIUC. Download POS tagger and shallow chunker [LBJPOS.jar, LBJChunk.jar, LBJ2.jar, LBJ2Library.jar] and put these in Tools/UIUC_TOOLs/ Install scikit-learn and scipy (instructions) Install java if not installed (instructions for Ubuntu) Make sure the Tools/SPADE_UTILS/bin/edubreak is set to executable.</description>
    </item>
    
    <item>
      <title>Discourse-informed Sen2Vec</title>
      <link>https://ntunlpsg.github.io/project/discourse-info-sen2vec/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/discourse-info-sen2vec/</guid>
      <description>About This resource contains the source code of CON-S2V: A Generic Framework for Incorporating Extra-Sentential Context into Sen2Vec Latent Representation for the sentences. paper.
Source code Link to source code
Requirements  Anaconda with Python 3.5 ROUGE-1.5.5  Python Environment setup and Update  Copy the sen2vec_environment.yml file into anaconda/envs folder Get into anaconda/envs folder. Run the following command:  conda env create -f sen2vec_environment.yml  Now, you have successfully installed sen2vec environment and now you can activate the environment using the following command.</description>
    </item>
    
    <item>
      <title>LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space</title>
      <link>https://ntunlpsg.github.io/project/lnmap/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/lnmap/</guid>
      <description>This resource contains the source code of our EMNLP-2020 paper entitled LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space.
Source code Link to source code
Datasets  Conneau et al. (2018) Dataset: Consists of FastText monolingual embeddings of 300 dimensions trained on Wikipedia monolingual corpus and gold dictionaries for 110 language pairs. Dinu-Artexe dataset: Consists of monolingual embeddings of 300 dimension for English, Italian and Spanish.</description>
    </item>
    
    <item>
      <title>Neural Domain Adaptation Model for Machine Translation</title>
      <link>https://ntunlpsg.github.io/project/neural-domain-adaptation-model-for-machine-translation/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/neural-domain-adaptation-model-for-machine-translation/</guid>
      <description>About This resource contain the source code of Domain adaptation using neural network joint model paper.
Source code Link to github
Publications Shafiq Joty, Nadir Durrani, Hassan Sajjad, and Ahmed Abdelali. Domain Adaptation Using Neural Network Joint Model. In Computer Speech &amp;amp; Language (Special Issue on Deep Learning for Machine Translation) : pages 161-179, 2017.
@article{joty-durrani-sajjad-abdelali-csl-17, title=&amp;quot;{Domain Adaptation Using Neural Network Joint Model}&amp;quot;, author={Shafiq Joty and Nadir Durrani and Hassan Sajjad and Ahmed Abdelali}, journal = {Computer Speech &amp;amp; Language}, volume={45}, publisher={Elsevier}, pages={161-179}, year={2017}, doi = {https://doi.</description>
    </item>
    
    <item>
      <title>Neural Local Coherence Model</title>
      <link>https://ntunlpsg.github.io/project/coherence/n-coh-acl17/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/coherence/n-coh-acl17/</guid>
      <description>About This resource contains the source code of &amp;ldquo;A Neural Local Coherence Model&amp;rdquo; paper. Source code Link to source code
Citation If you use the entity grid files (including permutations) and the code, please refer to our ACL 2017 paper.
@inproceedings{tiennguyen2017, author = {Tien Nguyen, Dat and Joty, Shafiq}, title = {A Neural Local Coherence Model}, booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, month = {July}, year = {2017}, address = {Vancouver, Canada}, publisher = {Association for Computational Linguistics}, pages = {1320--1330}, url = {http://aclweb.</description>
    </item>
    
    <item>
      <title>Recurrent Neural Models for Fine-grained Opinion Analysis</title>
      <link>https://ntunlpsg.github.io/project/opinion-analysis/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/opinion-analysis/</guid>
      <description>Publications Pengfei Liu, Shafiq Joty, Helen Meng. Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2015), Lisbon, Portugal, 2015.
@InProceedings{liu-joty-meng-emnlp-15, author = {Liu, Pengfei and Joty, Shafiq and Meng, Helen}, title = {Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings}, booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, year = {2015}, address = {Lisbon, Portugal}, series = {EMNLP&#39;15}, pages = {1433--1443}, url = {http://aclweb.</description>
    </item>
    
    <item>
      <title>Speech act recognizer for synchronous and asynchronous conversations</title>
      <link>https://ntunlpsg.github.io/project/speech-act/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/speech-act/</guid>
      <description>About This resource includes,
 A bi-directional LSTM for speech act recognition (theano, keras) A global CRF model for thread-level inference (Matlab) Tensorflow implementation of all the models presented in the Journal version. Tensorflow implementation of all the models presented in the NAACL-HLT 2019 paper. A web demo.  Related publications  Shafiq Joty and Enamul Hoque. 2016. Speech Act Modeling of Written Asynchronous Conversations with Task-Specific Embeddings and Conditional Structured Models.</description>
    </item>
    
    <item>
      <title>Topic Segmenter &amp; Labeler for Asynchronous Conversations</title>
      <link>https://ntunlpsg.github.io/project/topic-segmenter/</link>
      <pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/topic-segmenter/</guid>
      <description>Topic Segmentation and Labeling in Asynchronous Conversations Topic segmentation and labeling is often considered a prerequisite for higher-level conversation analysis and has been shown to be useful in many Natural Language Processing (NLP) applications. We present two new corpora of email and blog conversations annotated with topics, and evaluate annotator reliability for the segmentation and labeling tasks in these asynchronous conversations. We propose a complete computational framework for topic segmentation and labeling in asynchronous conversations.</description>
    </item>
    
    <item>
      <title>SegBot: A Generic Neural Text Segmentation Model with Pointer Network</title>
      <link>https://ntunlpsg.github.io/project/segbot/</link>
      <pubDate>Mon, 18 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/segbot/</guid>
      <description>Online Demo Figure 1 shows the model architecture of SegBot. For EDU segmentation, the units in the input $ U0 \ to \ U8 $ are words in a sentence. Formally, given an input sequence $ U = (U_1, U_2, &amp;hellip; , U_N) $ of length $N$, we get its distributed representations $ X = (x_1, x_2, &amp;hellip; , x_N $ by looking up the corresponding embedding matrix, where $x_n \in R^k$ is the representation for the unit $U_n$ with $K$ being the dimensions.</description>
    </item>
    
    <item>
      <title>Differentiable Window for Dynamic Local Attention]</title>
      <link>https://ntunlpsg.github.io/project/dynamic-attention/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/dynamic-attention/</guid>
      <description>Differentiable Window for Dynamic Local Attention This resource contains the source code of our ACL-2020 paper entitled Differentiable Window for Dynamic Local Attention
Source code Code
Citation Please cite our paper if you found the resources in this repository useful.
@inproceedings{nguyen-etal-2020-differentiable, title = &amp;quot;Differentiable Window for Dynamic Local Attention&amp;quot;, author = &amp;quot;Nguyen, Thanh-Tung and Nguyen, Xuan-Phi and Joty, Shafiq and Li, Xiaoli&amp;quot;, booktitle = &amp;quot;Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics&amp;quot;, month = jul, year = &amp;quot;2020&amp;quot;, address = &amp;quot;Online&amp;quot;, publisher = &amp;quot;Association for Computational Linguistics&amp;quot;, url = &amp;quot;https://www.</description>
    </item>
    
    <item>
      <title>Efficient Constituency Parsing by Pointing</title>
      <link>https://ntunlpsg.github.io/project/ptr-constituency-parser/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ntunlpsg.github.io/project/ptr-constituency-parser/</guid>
      <description>Efficient Constituency Parsing by Pointing This resource contains the source code of our ACL-2020 paper entitled Efficient Constituency Parsing by Pointing
Source code Code
Running Experiments For english parsing, run command
bash ./run_en.sh
For other parsing, run command
bash ./run_spmrl.sh
Citation Please cite our paper if you found the resources in this repository useful.
@inproceedings{nguyen-etal-2020-efficient, title = &amp;quot;Efficient Constituency Parsing by Pointing&amp;quot;, author = &amp;quot;Nguyen, Thanh-Tung and Nguyen, Xuan-Phi and Joty, Shafiq and Li, Xiaoli&amp;quot;, booktitle = &amp;quot;Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics&amp;quot;, month = jul, year = &amp;quot;2020&amp;quot;, address = &amp;quot;Online&amp;quot;, publisher = &amp;quot;Association for Computational Linguistics&amp;quot;, url = &amp;quot;https://www.</description>
    </item>
    
  </channel>
</rss>