<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.41" />
  

  
  
  
  
    
      
    
  
  <meta name="description" content="About This repository will host Python implementation of a number of deep neural networks classifiers for the classification of crisis-related data on Twitter.
 Requirementes:
python 2.7 numpy, scikit-learn keras, tensorflow or theano backend  Dataset and Pre-process A sample of tweet data (data/sample.csv) is a .csv format with three columns
First, we need to pre-process tweets data: remove urls, special characters, lowercasing… - python data_helpers/preprocess.py data/sample.csv Split pre-processed data (data/sample_prccd.">

  
  <link rel="alternate" hreflang="en-us" href="https://ntunlpsg.github.io/project/crisis-computing/">

  


  

  
  
  <meta name="theme-color" content="#0095eb">
  
  
  
  
    
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-115450637-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="https://ntunlpsg.github.io/index.xml" type="application/rss+xml" title="NTU-NLP">
  <link rel="feed" href="https://ntunlpsg.github.io/index.xml" type="application/rss+xml" title="NTU-NLP">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://ntunlpsg.github.io/project/crisis-computing/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@ntunlpsg">
  <meta property="twitter:creator" content="@ntunlpsg">
  
  <meta property="og:site_name" content="NTU-NLP">
  <meta property="og:url" content="https://ntunlpsg.github.io/project/crisis-computing/">
  <meta property="og:title" content="Deep Learning for Crisis Computing | NTU-NLP">
  <meta property="og:description" content="About This repository will host Python implementation of a number of deep neural networks classifiers for the classification of crisis-related data on Twitter.
 Requirementes:
python 2.7 numpy, scikit-learn keras, tensorflow or theano backend  Dataset and Pre-process A sample of tweet data (data/sample.csv) is a .csv format with three columns
First, we need to pre-process tweets data: remove urls, special characters, lowercasing… - python data_helpers/preprocess.py data/sample.csv Split pre-processed data (data/sample_prccd."><meta property="og:image" content="https://ntunlpsg.github.io/img/nn.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2016-04-28T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2016-04-28T00:00:00&#43;00:00">
  

  

  <title>Deep Learning for Crisis Computing | NTU-NLP</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/"><img src="/img/ntunlp_final.png" alt="NTU-NLP"></a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#people">
            
            <span>People</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/publication/">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/resources/">
            
            <span>Resources</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/post/reading-group">
            
            <span>Reading Group</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/post/monthly-nlp-talk/">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article article-project" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  <img src="/img/nn.png" class="article-banner" itemprop="image">
  
</div>



  <div class="article-container">

    <div class="pub-title">
      <h1 itemprop="name">Deep Learning for Crisis Computing</h1>
      <span class="pub-authors" itemprop="author">&nbsp;</span>
      <span class="pull-right">
        

      </span>
    </div>

    

    <div class="article-style" itemprop="articleBody">
      

<h3 id="about">About</h3>

<p><a href="https://github.com/CrisisNLP/deep-learning-for-big-crisis-data" target="_blank">This repository</a> will host Python implementation of a number of deep neural networks classifiers
for the classification of crisis-related data on Twitter.</p>

<ol>
<li><p>Requirementes:</p>

<pre><code>python 2.7
numpy, scikit-learn
keras, tensorflow or theano backend
</code></pre></li>

<li><p>Dataset and Pre-process
A sample of tweet data (data/sample.csv) is a .csv format with three columns</p>

<pre><code>First, we need to pre-process tweets data: remove urls, special characters, lowercasing…

- python data_helpers/preprocess.py data/sample.csv

Split pre-processed data (data/sample_prccd.csv) into train, test and dev part.

- python data_helpers/split_data.py data/sample_prccd.csv
</code></pre></li>

<li><p>Training a neural net model</p>

<p>To train a classifier we create a folder containing links to train, test and dev part (data/nn_data)</p>

<p>Folder embeddings/ includes word vector file, we provide our pre-trained crisis word vectors, we also can use Google word embedding here</p>

<p>Folder dnn_scrips/ contains all neural nets models: CNN, RNN_LSTM, MLP…</p>

<ul>
<li>bash run_cnn.sh to train a model with different parameters.</li>
</ul>

<p>See the results and training process in .log file</p>

<pre><code>Note that: if you do not have a GPU, you can run on CPU by change the theano flag to THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32
</code></pre></li>
</ol>

<h3 id="publication">Publication</h3>

<p>Dat Nguyen, Kamela Ali, Shafiq Joty, Hassan Sajjad, Muhammad Imran, and Prasenjit Mitra. Robust Classification of Crisis-Related Data on Social Networks Using Convolutional Neural Networks . In Proceedings of the Eleventh International Conference on Web and Social Media (ICWSM&rsquo;17) , pages 632-635, 2017.</p>

<pre><code>@InProceedings{nguyen-et-al-icwsm-17,
  author = {Dat Nguyen and Kamela Ali Al Mannai and Shafiq Joty and Hassan Sajjad and Muhammad Imran and Prasenjit Mitra},
  title = {Robust Classification of Crisis-Related Data on Social Networks Using Convolutional Neural Networks},
  booktitle = {Proceedings of the Eleventh International Conference on Web and Social
               Media},
  month     = {May},
  year      = {2017},
  series    = {ICWSM'17},
  address   = {Montr{\'{e}}al, Qu{\'{e}}bec, Canada},
  publisher = {AAAI},
  pages     = {xx--xx},
  url       = {papers/nguyen-et-al-icwsm-17.pdf},
  pages     = {632--635},
}
</code></pre>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/misc">misc</a>
  
</div>




    
    
    

    
      
      
      
      

      
      
      
      
    

  </div>
</article>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      ntunlp &copy; 2020 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

